{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f50e0db-7150-4c17-8fd7-e4ecf5b9b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import ConvLSTM2D, MaxPooling3D, TimeDistributed, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d959abc7-9b6c-4193-a059-40db5c28b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted at /home/fahim/Music/CarsDataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths\n",
    "dataset_path = \"/home/fahim/Music/CarsDataset.zip\"\n",
    "extracted_path = \"/home/fahim/Music/CarsDataset\"\n",
    "\n",
    "# Extract dataset\n",
    "if not os.path.exists(extracted_path):\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "else:\n",
    "    print(f\"Dataset already extracted at {extracted_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf7b768-9c15-4425-bee1-fdb70e67ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img = img.resize(target_size)\n",
    "        img_array = np.array(img) / 255.0\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19a3e29-fdda-416f-b482-16524062ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create data combinations\n",
    "def create_data_combinations(image_folder):\n",
    "    images, labels = [], []\n",
    "    class_mapping = {\n",
    "        'Audi': 0,\n",
    "        'Rolls Royce': 1,\n",
    "        'Toyota_celica': 2,\n",
    "        'Toyota_hilux': 3,\n",
    "        'Toyota_supra': 4,\n",
    "        'BMW': 5,\n",
    "        'Swift': 6,\n",
    "        'Toyota_corolla': 7,\n",
    "        'Toyota Innova': 8,\n",
    "        'Toyota_yaris': 9,\n",
    "        'Hyundai Creta': 10,\n",
    "        'Tata Safari': 11,\n",
    "        'Toyota_corona': 12,\n",
    "        'Toyota_prius': 13,\n",
    "        'Lamborghini': 14,\n",
    "        'Toyota_alphard': 15,\n",
    "        'Toyota_crown': 16,\n",
    "        'Toyota_rav4': 17,\n",
    "        'Mahindra Scorpio': 18,\n",
    "        'Toyota_avanza': 19,\n",
    "        'Toyota_fortuner': 20,\n",
    "        'Toyota_rush': 21,\n",
    "        'Mercedes': 22,\n",
    "        'Toyota_camry': 23,\n",
    "        'Toyota_hiace': 24\n",
    "    }\n",
    "\n",
    "    for class_folder in os.listdir(image_folder):\n",
    "        class_path = os.path.join(image_folder, class_folder)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            img_data = load_and_preprocess_image(image_path)\n",
    "            if img_data is not None:\n",
    "                images.append(img_data)\n",
    "                label = class_mapping[class_folder]\n",
    "                labels.append(label)\n",
    "        print(f\"Loaded images from class: {class_folder}\")\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b15695-4b68-4640-9965-a0dbe7d940ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from class: Toyota_supra\n",
      "Loaded images from class: Toyota_hilux\n",
      "Loaded images from class: Audi\n",
      "Loaded images from class: Toyota_rav4\n",
      "Loaded images from class: Toyota_corona\n",
      "Loaded images from class: Toyota_camry\n",
      "Loaded images from class: Toyota_alphard\n",
      "Loaded images from class: Rolls Royce\n",
      "Loaded images from class: Toyota_corolla\n",
      "Loaded images from class: Tata Safari\n",
      "Loaded images from class: Swift\n",
      "Loaded images from class: Toyota_hiace\n",
      "Loaded images from class: BMW\n",
      "Loaded images from class: Toyota_prius\n",
      "Loaded images from class: Toyota_crown\n",
      "Loaded images from class: Toyota Innova\n",
      "Loaded images from class: Toyota_rush\n",
      "Loaded images from class: Toyota_fortuner\n",
      "Loaded images from class: Mercedes\n",
      "Loaded images from class: Toyota_yaris\n",
      "Loaded images from class: Hyundai Creta\n",
      "Loaded images from class: Lamborghini\n",
      "Loaded images from class: Toyota_avanza\n",
      "Loaded images from class: Toyota_celica\n",
      "Loaded images from class: Mahindra Scorpio\n"
     ]
    }
   ],
   "source": [
    "# image_folder = os.path.join(extracted_path, 'train')\n",
    "\n",
    "image_folder = '/home/fahim/Music/CarsDataset/train'\n",
    "images, labels = create_data_combinations(image_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f842ccb-ad5d-4941-ab7e-812800f2714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_image: (1080, 1, 224, 224, 3)\n",
      "Shape of Y_labels: (1080,)\n"
     ]
    }
   ],
   "source": [
    "X_image = np.array(images)\n",
    "Y_labels = np.array(labels)\n",
    "X_image = np.expand_dims(X_image, axis=1)\n",
    "\n",
    "print(\"Shape of X_image:\", X_image.shape)\n",
    "print(\"Shape of Y_labels:\", Y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7338e6-969b-4a6b-a686-5e620e46369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_image, Y_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44b18b-65f6-4128-af4a-156fd9463f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db164636-37fb-42a1-abf1-ece2d69b1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convlstm_model(input_shape, class_mapping_length):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh', return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh', return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    model.add(ConvLSTM2D(filters=14, kernel_size=(3, 3), activation='tanh', return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh', return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(class_mapping_length, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6fc26-b81c-4e16-9791-038d6c66b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = X_train.shape[1:]\n",
    "# model = create_convlstm_model(input_shape)\n",
    "# model.summary()\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=1, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# # Evaluate model\n",
    "# loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "# print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# model_path = \"/home/fahim/Music/car_model_classifier_convlstm2.h5\"\n",
    "# model.save(model_path)\n",
    "# print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "# # Function to preprocess locally uploaded image\n",
    "# def preprocess_local_image(image_path):\n",
    "#     try:\n",
    "#         img = cv2.imread(image_path)\n",
    "#         img = cv2.resize(img, (224, 224))  # Resize image\n",
    "#         img = img.astype('float32') / 255.0\n",
    "#         return img\n",
    "#     except Exception as e:\n",
    "#         print(\"Error:\", str(e))\n",
    "#         return None\n",
    "\n",
    "# # Function to predict car model from a local image file\n",
    "# def predict_car_model_local(image_path, model, class_mapping):\n",
    "#     preprocessed_image = preprocess_local_image(image_path)\n",
    "#     if preprocessed_image is None:\n",
    "#         return None\n",
    "    \n",
    "#     preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "#     preprocessed_image = np.expand_dims(preprocessed_image, axis=1)\n",
    "#     prediction = model.predict(preprocessed_image)\n",
    "#     predicted_label_index = np.argmax(prediction)\n",
    "#     return class_mapping.get(predicted_label_index, \"Unknown\")\n",
    "\n",
    "# class_mapping = {\n",
    "#     0: 'Audi',\n",
    "#     1: 'Rolls Royce',\n",
    "#     2: 'Toyota_celica',\n",
    "#     3: 'Toyota_hilux',\n",
    "#     4: 'Toyota_supra',\n",
    "#     5: 'BMW',\n",
    "#     6: 'Swift',\n",
    "#     7: 'Toyota_corolla',\n",
    "#     8: 'Toyota Innova',\n",
    "#     9: 'Toyota_yaris',\n",
    "#     10: 'Hyundai Creta',\n",
    "#     11: 'Tata Safari',\n",
    "#     12: 'Toyota_corona',\n",
    "#     13: 'Toyota_prius',\n",
    "#     14: 'Lamborghini',\n",
    "#     15: 'Toyota_alphard',\n",
    "#     16: 'Toyota_crown',\n",
    "#     17: 'Toyota_rav4',\n",
    "#     18: 'Mahindra Scorpio',\n",
    "#     19: 'Toyota_avanza',\n",
    "#     20: 'Toyota_fortuner',\n",
    "#     21: 'Toyota_rush',\n",
    "#     22: 'Mercedes',\n",
    "#     23: 'Toyota_camry',\n",
    "#     24: 'Toyota_hiace'\n",
    "# }\n",
    "\n",
    "# uploaded_image_path = '/home/fahim/Downloads/rr3.jpeg'  # Replace with your image path\n",
    "# model = load_model(model_path)\n",
    "# predicted_car_model = predict_car_model_local(uploaded_image_path, model, class_mapping)\n",
    "\n",
    "# if predicted_car_model is not None:\n",
    "#     print(\"Predicted Car Model:\", predicted_car_model)\n",
    "# else:\n",
    "#     print(\"Prediction failed. Please check your image path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89695183-e313-4801-b7af-7e501806b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'Audi': 0,\n",
    "    'Rolls Royce': 1,\n",
    "    'Toyota_celica': 2,\n",
    "    'Toyota_hilux': 3,\n",
    "    'Toyota_supra': 4,\n",
    "    'BMW': 5,\n",
    "    'Swift': 6,\n",
    "    'Toyota_corolla': 7,\n",
    "    'Toyota Innova': 8,\n",
    "    'Toyota_yaris': 9,\n",
    "    'Hyundai Creta': 10,\n",
    "    'Tata Safari': 11,\n",
    "    'Toyota_corona': 12,\n",
    "    'Toyota_prius': 13,\n",
    "    'Lamborghini': 14,\n",
    "    'Toyota_alphard': 15,\n",
    "    'Toyota_crown': 16,\n",
    "    'Toyota_rav4': 17,\n",
    "    'Mahindra Scorpio': 18,\n",
    "    'Toyota_avanza': 19,\n",
    "    'Toyota_fortuner': 20,\n",
    "    'Toyota_rush': 21,\n",
    "    'Mercedes': 22,\n",
    "    'Toyota_camry': 23,\n",
    "    'Toyota_hiace': 24\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc45a84-90e0-4d1d-b986-ec32d9ddbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/fahim/Music/car_model_classifier_convlstm2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5549d5fc-1057-4ef7-9081-8be03ed8c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model found. Training a new model.\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 400ms/step - accuracy: 0.0474 - loss: 3.2178 - val_accuracy: 0.0324 - val_loss: 3.2033\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 381ms/step - accuracy: 0.0480 - loss: 3.1930 - val_accuracy: 0.0278 - val_loss: 3.1918\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 381ms/step - accuracy: 0.0402 - loss: 3.1936 - val_accuracy: 0.0278 - val_loss: 3.1859\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 380ms/step - accuracy: 0.0372 - loss: 3.1787 - val_accuracy: 0.0278 - val_loss: 3.1849\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 382ms/step - accuracy: 0.0446 - loss: 3.1772 - val_accuracy: 0.0278 - val_loss: 3.1838\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 382ms/step - accuracy: 0.0404 - loss: 3.1794 - val_accuracy: 0.0278 - val_loss: 3.1846\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 383ms/step - accuracy: 0.0444 - loss: 3.1779 - val_accuracy: 0.0278 - val_loss: 3.1788\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 384ms/step - accuracy: 0.0398 - loss: 3.1770 - val_accuracy: 0.0509 - val_loss: 3.1666\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 417ms/step - accuracy: 0.0760 - loss: 3.1197 - val_accuracy: 0.0648 - val_loss: 3.1492\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 383ms/step - accuracy: 0.1369 - loss: 3.0575 - val_accuracy: 0.0787 - val_loss: 3.1053\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 401ms/step - accuracy: 0.1518 - loss: 2.9487 - val_accuracy: 0.0926 - val_loss: 3.1094\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 383ms/step - accuracy: 0.1633 - loss: 2.8474 - val_accuracy: 0.0972 - val_loss: 3.0319\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 418ms/step - accuracy: 0.2083 - loss: 2.8000 - val_accuracy: 0.0833 - val_loss: 3.1508\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 418ms/step - accuracy: 0.2186 - loss: 2.6294 - val_accuracy: 0.1065 - val_loss: 3.1707\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 417ms/step - accuracy: 0.3123 - loss: 2.3849 - val_accuracy: 0.0926 - val_loss: 3.3377\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 422ms/step - accuracy: 0.4331 - loss: 2.0419 - val_accuracy: 0.1019 - val_loss: 3.4552\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 419ms/step - accuracy: 0.5017 - loss: 1.7738 - val_accuracy: 0.1111 - val_loss: 3.6504\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 419ms/step - accuracy: 0.6217 - loss: 1.4398 - val_accuracy: 0.1111 - val_loss: 3.8786\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 379ms/step - accuracy: 0.7267 - loss: 1.1165 - val_accuracy: 0.1019 - val_loss: 4.1980\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 381ms/step - accuracy: 0.7948 - loss: 0.9031 - val_accuracy: 0.1157 - val_loss: 4.3687\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 386ms/step - accuracy: 0.8469 - loss: 0.7171 - val_accuracy: 0.1204 - val_loss: 4.6185\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 450ms/step - accuracy: 0.9101 - loss: 0.5640 - val_accuracy: 0.1111 - val_loss: 4.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /home/fahim/Music/car_model_classifier_convlstm2.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "# Load the pre-trained model or train a new one\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading pre-trained model from:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    print(\"No pre-trained model found. Training a new model.\")\n",
    "    input_shape = X_train.shape[1:]\n",
    "    class_mapping_length = len(class_mapping)\n",
    "    model = create_convlstm_model(input_shape, class_mapping_length)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "291dc9fa-7058-4db0-b6a9-8579d358bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0974 - loss: 3.0343\n",
      "Test Accuracy: 9.72%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3526f90f-396b-4214-ac38-3c801b3e0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess locally uploaded image\n",
    "def preprocess_local_image(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (224, 224))  # Resize image\n",
    "        img = img.astype('float32') / 255.0\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Function to predict car model from a local image file\n",
    "def predict_car_model_local(image_path, model, class_mapping):\n",
    "    preprocessed_image = preprocess_local_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return None\n",
    "    \n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=1)\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    predicted_label_index = np.argmax(prediction)\n",
    "    return class_mapping.get(predicted_label_index, \"Unknown\")\n",
    "\n",
    "class_mapping = {\n",
    "    0: 'Audi',\n",
    "    1: 'Rolls Royce',\n",
    "    2: 'Toyota_celica',\n",
    "    3: 'Toyota_hilux',\n",
    "    4: 'Toyota_supra',\n",
    "    5: 'BMW',\n",
    "    6: 'Swift',\n",
    "    7: 'Toyota_corolla',\n",
    "    8: 'Toyota Innova',\n",
    "    9: 'Toyota_yaris',\n",
    "    10: 'Hyundai Creta',\n",
    "    11: 'Tata Safari',\n",
    "    12: 'Toyota_corona',\n",
    "    13: 'Toyota_prius',\n",
    "    14: 'Lamborghini',\n",
    "    15: 'Toyota_alphard',\n",
    "    16: 'Toyota_crown',\n",
    "    17: 'Toyota_rav4',\n",
    "    18: 'Mahindra Scorpio',\n",
    "    19: 'Toyota_avanza',\n",
    "    20: 'Toyota_fortuner',\n",
    "    21: 'Toyota_rush',\n",
    "    22: 'Mercedes',\n",
    "    23: 'Toyota_camry',\n",
    "    24: 'Toyota_hiace'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1514eba8-43aa-4275-a46d-d7ad499da49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "Predicted Car Model: Toyota_fortuner\n"
     ]
    }
   ],
   "source": [
    "uploaded_image_path = '/home/fahim/Downloads/rr2.jpeg'  # Replace with your image path\n",
    "predicted_car_model = predict_car_model_local(uploaded_image_path, model, class_mapping)\n",
    "\n",
    "if predicted_car_model is not None:\n",
    "    print(\"Predicted Car Model:\", predicted_car_model)\n",
    "else:\n",
    "    print(\"Prediction failed. Please check your image path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d1f1890-baed-4471-bcfe-3b97c9b00340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/fahim/Downloads/rr.jpeg')\n",
    "if img is not None:\n",
    "    print(\"Image loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6df3d0-c824-412a-a6e6-c593e890f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9478ade7-8e34-4234-a189-813ee5db52e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/fahim/anaconda3/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/fahim/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15226e09-2f8e-4145-bbf6-3a1da8757d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
